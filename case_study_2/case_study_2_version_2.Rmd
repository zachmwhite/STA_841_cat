---
title: "Case Study 2"
author: "Zach White"
date: "November 15, 2017"
output: pdf_document
fontsize: 12pt
geometry: margin=1in
---

```{r setup, include=FALSE, warnings = FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("knitr",repos = "http://cran.us.r-project.org")
install.packages("brms",repos = "http://cran.us.r-project.org")
install.packages("tidyverse",repos = "http://cran.us.r-project.org")
install.packages("magrittr",repos = "http://cran.us.r-project.org")
install.packages("gridExtra", repos = "http://cran.us.r-project.org")
install.packages("stringr", repos = "http://cran.us.r-project.org")
install.packages("rstan",repos = "http://cran.us.r-project.org")
setwd("C:/Users/Zachary/Desktop/Fall_2017_Projects/STA_841/STA_841_cat/case_study_2")
library(knitr)
library(tidyverse)
library(magrittr)
library(brms)
library(gridExtra)
library(rstan)
library(stringr)
```

```{r, echo = FALSE, results= 'hide'}
# Load the data
cs2 = read.csv("cs2.csv", header = TRUE, stringsAsFactors = FALSE)
colnames(cs2) = tolower(colnames(cs2))
colnames(cs2)[1] = "physician.name"
inv_logit = function(x) exp(x) / (1 + exp(x))
apply(table(cs2$hospital.name,cs2$physician.name), 2, function(x) sum(x > 0))
#cs2 = cs2 %>% mutate(obs.p.hat = number.of.deaths / number.of.cases,
#                     logit.obs.p = log(obs.p.hat / (1 - obs.p.hat)))

# logitobs.p by Expected mortality rate 
#ggplot(cs2, aes(x = expected.mortality.rate, y = logit.obs.p, group = procedure, color = procedure)) +
#  geom_point()

#ggplot(cs2, aes(x = detailed.region, y = logit.obs.p, group = procedure, color = procedure)) + geom_point()
#ggplot(cs2, aes(x = detailed.region, y = logit.obs.p, group = detailed.region, color = procedure)) + geom_boxplot()

cs2$detailed.region = factor(cs2$detailed.region)
cs2$detailed.region = relevel(cs2$detailed.region, ref = "Queens")

```

```{r, echo = FALSE, eval = FALSE}

# It asks for each combination of procedure and region. I will first test out like classical main and interaction effects
# And then I will test out just the interactions without the main effects
initial.model = brm(number.of.deaths | trials(number.of.cases) ~ (1| hospital.name) + (1 | physician.name) + detailed.region + procedure + procedure:detailed.region,
                    family = binomial("logit"),
                    data = cs2,
                    control = list(adapt_delta = .9)
                    )


rand.main = brm(number.of.deaths | trials(number.of.cases) ~ (1| hospital.name) + (1 | physician.name) + procedure + detailed.region,
                    family = binomial("logit"),
                    data = cs2
                    )




cs2.expanded = data_frame()
for(i in 1:nrow(cs2)){
  n.case = cs2$number.of.cases[i]
  n.deaths = cs2$number.of.deaths[i]
  base_frame = data_frame(
    physician.name = rep(cs2$physician.name[i],n.case),
    hospital.name = rep(cs2$hospital.name[i],n.case),
    detailed.region = rep(cs2$detailed.region[i],n.case),
    procedure = rep(cs2$procedure[i],n.case),
    death = rep(c(1,0),c(n.deaths,n.case - n.deaths))
  )
  cs2.expanded = bind_rows(cs2.expanded,base_frame)
}

bin.model = brm(death ~ (1| hospital.name) + (1 | physician.name) + detailed.region + procedure + procedure:detailed.region,
                family = bernoulli,
                data = cs2.expanded)



```

```{r, echo = FALSE}
#Finalized Models

# Load posterior draws if they already exist

if (!file.exists("final_model.Rdata")) {
    # Do posterior draws here.
   final.model = brm(number.of.deaths | trials(number.of.cases) ~ (1| hospital.name) + (1 | physician.name) + detailed.region + procedure + procedure:detailed.region,
                    family = binomial("logit"),
                    data = cs2,
                    control = list(adapt_delta = .85),
                    prior = set_prior("normal(0,4)",class = "b"),
                    iter = 5000
                    )
   save(final.model,file = "final_model.Rdata")

 } else{
   load("final_model.Rdata")
 }

rand.eff = ranef(final.model)
post.samp = posterior_samples(final.model)
sum.fin = summary(final.model)
```


##### Objective 1
```{r, echo = FALSE,strip.white=TRUE}
labels = levels(cs2$detailed.region)[-1]
region.effects = sum.fin$fixed
cabg.lower = unlist(exp(region.effects[2:11,3]))
cabg.upper = unlist(exp(region.effects[2:11,4]))
cabg.med = unlist(exp(region.effects[2:11,1]))
region.cabg.df = data_frame(labels = labels,cabg.lower = cabg.lower,cabg.upper = cabg.upper,cabg.med = cabg.med)
region.cabg.fp = ggplot(region.cabg.df, aes(x = labels, ymin = cabg.lower,y = cabg.med,ymax = cabg.upper)) +
    geom_pointrange()+
    geom_hline(yintercept = 1, lty = 2) +
    labs(subtitle = "Odds of Death of CABG to Queens CABG by REgion", y = "Median (95% CrI)") +
    coord_flip() +
    theme_bw()
# We don't include the intercept or the procedure because we ar doing an odds ratio between region valve and queens valve
valve.lower = exp( region.effects[2:11,3]  +region.effects[13:22,3])
valve.upper = exp( region.effects[2:11,4] +region.effects[13:22,4])
valve.med = exp(region.effects[2:11,1] +region.effects[13:22,1])
region.valve.df = data_frame(labels = labels,
                             valve.lower= valve.lower,
                             valve.upper = valve.upper,
                             valve.med = valve.med)
region.valve.fp = ggplot(region.valve.df,aes(x = labels, y = valve.med, ymin = valve.lower, ymax = valve.upper)) +
  geom_pointrange() +
  geom_hline(yintercept = 1, lty = 2) +
  labs(subtitle = "Odds of Death of Valve to Queens Valve by Region",
       y = "Median (95% CrI)") +
  coord_flip()+
  theme_bw()
```
The model form of the binomial generalized linear mixed model is the following:
$$
\text{log} \bigg(\frac{Pr(Y_{ijk} = y| N,\boldsymbol{\beta},\textbf{X})}{1 - Pr(Y_{ijk} = y| N,\boldsymbol{\beta},\textbf{X})}\bigg) = \beta_0 + \beta_{\text{region}} \text{R}_{ijk} + \beta_{\text{procedure}} \text{P}_{ijk}+ \beta_{\text{region:procedure}} \text{R}_{ijk} \text{P}_{ijk} + \text{h}_i+ \text{d}_j
$$
For the sake of ease of interpretation, we use a logit link instead of a probit link. Also, alternatively, we could expand this data into a table of bernoulli trials, but doing so increases computation time fitting our bayesian model, since there are $76,519$ total cases. We use a $N(0,\text{sd} = 4)$ priors on all $\beta$ coefficients.  Also, for the random effect for hospital $\text{h}_i \sim N(0,\sigma^2_{\text{hospital}})$ where $\sigma^2_{\text{hospital}}$ follows a folded stuent-t distribution with 3 degrees of freedom and a scale parameter of 10. For the random effect for physician, we use a similar prior structure as for the hospital random effect where $\text{d}_j \sim N(0,\sigma^2_{\text{physician}})$ where $\sigma^2_{\text{physician}}$ follows the same folded t-distribution. However, it is important to note that we leave these random effects inependent from one another. Once we fit this model and generate posterior draws for these random effects, we estimate that $\sigma_{\text{hospital}} = 0.11\ (0.01,.026)$ and $\sigma_{\text{physician}} = 0.37\ (0.29,0.46)$. The parenthetical values represent a central 90% credible interva. Although both of these are entirely above zero, it seems clear that $\sigma_{\text{physician}} > \sigma_{\text{hospital}}$, which indicates that there is more heterogeneity on the level of the doctor than that of the hospitals, which is not suprising. These are posterior estimates for the standard error for these random effects. If we are interested in the variance of these standard errors, we need to square these posterior draws and then find the relevant quantiles of interested. Doing this yields the following estimates: $\sigma^2_{\text{hospital}} = .011 (0.00013,0.055)$ and $\sigma^2_{\text{physician}} = 0.137\ (0.0897,0.201)$ which are obviously smaller since these values were already less than 1.  For the rest of the report, when we reference a credible interval, it reers to a 95% credible interval.

```{r, echo = FALSE}
  
grid.arrange(region.cabg.fp,region.valve.fp, ncol = 1)
```
 
The above plot shows the posterior medians and a 95% credible interval for the odds-ratios comparing
the odds of death in each region to that in Queens for each of the two procedures.


##### Objective 2
```{r, echo = FALSE}
names(post.samp) = names(post.samp) %>% str_replace("r\\_physician.name\\[","") %>%
  str_replace("r\\_hospital.name\\[","") %>%
  str_replace("\\,Intercept\\]","")

cs2$expected.mortality.rate.real = cs2$expected.mortality.rate / 100

prob.mat = matrix(0, ncol = nrow(cs2),nrow = 10000)

for(i in 1:nrow(cs2)){
  physician = cs2$physician.name[i] %>% str_replace_all(" ",".")
  hospital = cs2$hospital.name[i] %>% str_replace(" ",".")
  region = cs2$detailed.region[i]  %>% as.character() %>% str_replace_all(" ","") %>% str_replace_all("\\-","")
  procedure = cs2$procedure[i]
  
  match.phys = agrep(physician,names(post.samp))
  match.hosp = agrep(hospital,names(post.samp))
  match.region = agrep(region,names(post.samp))
  
  #Random Effects
  rand.ind = post.samp[,match.phys] + post.samp[,match.hosp]
  if(procedure == "CABG"){
    if(region == "Queens"){
      nu = rand.ind  + post.samp[,1] 
    } else{
      nu = rand.ind + post.samp[,1] + post.samp[,match.region[1]]
    }
  } else{
    if(region == "Queens"){
      nu = rand.ind + post.samp[,1] + post.samp[,12] 
    } else {
      nu = rand.ind + post.samp[,1] + post.samp[,12] + post.samp[,match.region[1]] + post.samp[,match.region[2]]
    }
  }
  prob = inv_logit(nu)
  prob.mat[,i] = prob
  ratio = prob / cs2$expected.mortality.rate.real[i]
  rat.more.1 = mean(ratio > 1)
  cs2$prob.rat.more.1[i] = rat.more.1
  cs2$lower.prob[i] = quantile(prob,.025)
  cs2$med.prob[i]= quantile(prob,.5)
  cs2$upper.prob[i] = quantile(prob,.975)
  cs2$lower.ratio[i] = quantile(ratio,.025)
  cs2$med.ratio[i]= quantile(ratio,.5)
  cs2$upper.ratio[i]= quantile(ratio,.975)
  cs2$above.95[i] = rat.more.1 > .95
  cs2$below.05[i] = rat.more.1 < .05
}

cs2 = cs2 %>% mutate(procedure = ifelse(procedure == "CABG","CABG","Valve"),
                     lower.prob = round(lower.prob,4),
                     med.prob = round(med.prob,4),
                     upper.prob = round(upper.prob,4),
                     lower.ratio = round(lower.ratio,4),
                     med.ratio = round(med.ratio,4),
                     upper.ratio = round(upper.ratio,4),
                     prob.rat.more.1 = round(prob.rat.more.1,4)
                     )
```
The following forest plot shows the different combinations of observed doctors, hospitals, and procedure type. There are a lot of doctors in these data, and thus, we do display all the names of the doctors in this plot. The plot on the left shows the  ratio of modeled rate of mortality to expected mortality rate (which takes case mixture into consideration) for CABG procedures. It is important to note that if this ratio is less than one, then the doctor’s mortality rate is lower than expected, and thus this doctor is performing better than expected. If the ratio is greater than 1, it indicates that the doctor is underperforming in regards to expected mortality rate.  Also, on the plot is a dotted line at the one, which would indicate that the physician is performing as well as we would expect. Analyzing these plots, it seems as though there are more doctors whose ratio is greater than one when performing the valve or valve/CABG operation than when performing CABG. CABG seems higher variance in general, but there are also less doctors doing worse than expected.
```{r, echo = FALSE,fig.height=3.5,strip.white=TRUE}
ggplot(cs2, aes(physician.name,y = med.ratio, ymin = lower.ratio, ymax = upper.ratio)) +
  geom_pointrange(fill = "blue", color = "grey", shape = 21, size = .25) + 
  geom_hline(yintercept = 1, lty = 2) + 
  facet_grid(~procedure) +
  coord_flip()+
  labs(title = "Credible Interval of Ratio by physician and procedure",
       ylab = NULL,
       xlab = "Ratio") + 
  scale_x_discrete(breaks = 20) +
  theme_bw()

```
The following table shows the attributes of physicians with a posterior probability of the ratio being greater than 1 of less than 0.05. In other words, these are physicians with a 0.95 probability of exceding expectations.

```{r, echo = FALSE,strip.white=TRUE}
cs2 %>% filter(below.05) %>%
  select(physician.name,hospital.name,procedure,med.prob,lower.prob,upper.prob,prob.rat.more.1) %>%
  rename("physician" = physician.name,
         "hospital" = hospital.name,
         "proc" = procedure,
         "Rate Est." = med.prob,
         "Lower" = lower.prob,
         "Upper" = upper.prob,
         "Pr(R>1)" = prob.rat.more.1) %>%
  kable(.)
```

This table shows the physicians whose ratio has a posterior probability of exceding 1 of greater than 0.95. In other words, these are physicians with a high probability of doing worse than expected, since a ratio of greater than 1 indicates that the modeled rate is greater than the expected mortality rate.

```{r, echo = FALSE,strip.white=TRUE}
cs2 %>% filter(above.95) %>% select(physician.name,hospital.name,procedure,med.prob,lower.prob,upper.prob,prob.rat.more.1) %>%
  rename("physician" = physician.name,
         "hospital" = hospital.name,
         "proc" = procedure,
         "Rate Est." = med.prob,
         "Lower" = lower.prob,
         "Upper" = upper.prob,
         "Pr(R>1)" = prob.rat.more.1) %>%
  kable(., padding = 0)
```


##### Objective 3
Dr. Tortolani has performed these procedures at both the NY Methodist Hospital and NYP-Weill Cornell. To assess whether Dr. Tortolani has a higher mortality rate than expected, we will use information from both these hospitals. The following table shows which the Observed Mortality Ratio(OMR), Expected Mortality Ratio (EMR), median and credible interval for the ratio between modeled mortality rate and EMR, and the posterior probability of whether that ratio is greater than 1.
```{r, echo  = FALSE,strip.white=TRUE}
cs2 %>% filter(physician.name == "Tortolani A") %>%
  select(hospital.name,procedure, number.of.cases, observed.mortality.rate, expected.mortality.rate,med.ratio,lower.ratio,upper.ratio,prob.rat.more.1) %>%
  rename("hospital" = hospital.name,
         "n" = number.of.cases,
         "OMR" = observed.mortality.rate,
         "proc" = procedure,
         "EMR" = expected.mortality.rate,
         "m.Ratio" = med.ratio,
         "Lower" = lower.ratio,
         "Upper" = upper.ratio,
         "Pr(R>1)" = prob.rat.more.1) %>%
  kable(., padding = 0)
```


Within the Methodist hospital, there is 0.97 or 0.93 probability that Dr. Tortolani is doing worse than expected in CABG and valve or valve/CABG procedures. These both are quite high.  Understanding that Dr. Tortolani also has performed these procedures at Cornell is important. However, this information added is clearly limited since he has only performed 4 CABG and 5 valve procedures there. At the Weill Cornell Hospital, the probability that the ratios are greater than 1 is 0.843 and 1.00 for the CABG and valve procedures, resepectively. These probabilities reflect a smaller sample size and higher observed mortality rate. Based mostly the ratio for the Methodist Hospital, there seems to be evidence that Dr. Tortolani is doing worse than expected in these procedures.

##### Objective 4
The following table shows similar information as the previous table. However, this is for each doctor at NYP-Columbia Presbyterian Hospital, including the doctors who also work elsewhere and their respective hospitals. However, for this, we also include the total number of cases for each of the doctors because it helps to quantify our uncertainty better in this context.

```{r, echo = FALSE,strip.white=TRUE}
pres.doctors = cs2 %>% filter(hospital.name == "NYP- Columbia Presby.") %>%
  .[["physician.name"]]
cs2 %>% filter(physician.name %in% pres.doctors) %>%
  select(physician.name,hospital.name,procedure, number.of.cases, observed.mortality.rate, expected.mortality.rate,med.ratio,lower.ratio,upper.ratio,prob.rat.more.1) %>%
  mutate(hospital.name = ifelse(hospital.name == "NYP- Columbia Presby.", "C. Presby","W. Cornell")) %>%
  rename("physician" = physician.name,
         "hospital" = hospital.name,
         "n" = number.of.cases,
         "OMR" = observed.mortality.rate,
         "proc" = procedure,
         "EMR" = expected.mortality.rate,
         "m.Ratio" = med.ratio,
         "Lower" = lower.ratio,
         "Upper" = upper.ratio,
         "Pr(R>1)" = prob.rat.more.1) %>%
  kable(., padding = 0)

```

Using this information, we could set a probability threshold of the ratio between modeled mortality rates and EMR to decide whether there should be concern for any of the clinicians’ performance. To illustrate, we decide that the threshold is that if there is 0.80 probability that a doctor is underperforming, then we should be concerned. Under these conditions, we should be concerned about the valve operations for doctors Argenziano, Chen, Naka, Quaegebeur, and Stewart (no CABG procedures meet this criteria). If we investigate this further, we see that both Checn and Quaeagebeur have an extremely small procedure loads, and so this probability is only reflective of prior and population information. Check and Naka both perform very little operations at NYP-Weill Cornell, and their ratio is also quite high, but the similar story holds. However, there should be concern for Argenziano, Naka, and Stewart because they all have high case-loads and high probability that they are underperforming.  Something that may be of concern with our model is that we are getting fairly certain results even when we have low sample sizes, which may indicate that our prior is too strong or that other factors are overwhelming the random effects for doctors

##### Objective 5
According to the table below, Dr. Ciaburri does not have an observed mortality in the data set, and thus his overall observed mortality rate is 0.  However, analyzing this number alone is not sufficient because it may be due to a relatively small procedue load.  Analzying credible interval for the ratios of modeled mortality rate to expected mortaility rate shows that Dr. Ciaburri does in fact exceed expectation, especially for the valve surgery in the Methodist hospital.  Also, observing the probability that their ratio is greater than 1 supports the idea that Dr. Ciaburri is exceeding expectation.  However, both of these measures are not complete for ranking physicians.

```{r, echo = FALSE,strip.white=TRUE}
cs2 %>% filter(physician.name == "Ciaburri D") %>%
  select(hospital.name,procedure, number.of.cases, observed.mortality.rate, expected.mortality.rate,med.ratio,lower.ratio,upper.ratio,prob.rat.more.1) %>%
  rename("hospital" = hospital.name,
         "n" = number.of.cases,
         "OMR" = observed.mortality.rate,
         "proc" = procedure,
         "EMR" = expected.mortality.rate,
         "m.Ratio" = med.ratio,
         "Lower" = lower.ratio,
         "Upper" = upper.ratio,
         "Pr(R>1)" = prob.rat.more.1) %>%
  kable(., padding = 0)
```

If I were to rank physicians, I would rank them according to their upper bound of the credible interval for the ratio of interest.  This way we can take into consideration the variance of these estimates, which is important, especially in rankings.  It desmonstrates how certain these estimates can be.  To make this less of a conditional ranking on hospital and procedure, we do a weighted average across the modeled probabilities and expected mortaility rate, weighting the number of cases from each physician.  Although this is ad-hoc, it makes sense to use it as a rating system for physicians or hospitals.  Doing it this way, we see that Dr. Ciaburri is ranked quite highly, but he is not the highest ranked physician, who is actualy Dr. Spielvogel. 

```{r, echo = FALSE,strip.white=TRUE, cache = TRUE}
top_15 = cs2 %>%
  select(physician.name,hospital.name,procedure, number.of.cases, observed.mortality.rate, expected.mortality.rate,med.ratio,lower.ratio,upper.ratio,prob.rat.more.1) %>%
  arrange(upper.ratio) %>%
  rename("physician" = physician.name,
         "hospital" = hospital.name,
         "n" = number.of.cases,
         "OMR" = observed.mortality.rate,
         "proc" = procedure,
         "EMR" = expected.mortality.rate,
         "m.Ratio" = med.ratio,
         "Lower" = lower.ratio,
         "Upper" = upper.ratio) %>%
  top_n(.,n=15,-Upper)
```

```{r, echo = FALSE,cache = TRUE}
unique.phys = unique(cs2$physician.name)
#prob.mat
physician.rat.df = data_frame()
for(phys in unique.phys){
  phys.mat = prob.mat[,which(cs2$physician.name == phys)]
  if(sum(cs2$physician.name == phys) > 1){
    ave.vec = apply(phys.mat,1,function(x) weighted.mean(x,cs2$number.of.cases[cs2$physician.name == phys]))
    ave.epr = weighted.mean(cs2$expected.mortality.rate.real[cs2$physician.name == phys],cs2$number.of.cases[cs2$physician.name == phys])
  } else {
    ave.vec = phys.mat
    ave.epr = cs2$expected.mortality.rate.real[cs2$physician.name == phys]
  }
  phys.ratio = ave.vec / ave.epr
  phys.n = sum(cs2$number.of.cases[which(cs2$physician.name == phys)])
  df = data_frame(name = phys, 
                  total.n = phys.n,
                  med.ratio = quantile(phys.ratio,.5),
                  lower.ratio = quantile(phys.ratio,0.025),
                  upper.ratio = quantile(phys.ratio,.975),
                  prob.above.1 = mean(phys.ratio > 1))
  physician.rat.df = bind_rows(physician.rat.df,df)
  
}

physician.rat.df %>% arrange(upper.ratio) %>% head(n = 15) %>%
  kable(.)

```


##### Objective 6
To recognize high and low achieving hospitals, we use a similar process as we do for the physicians.  We use the posterior samples for the modeled rates for each of the combinations of the physicians and the procedures.  We then average these modeled rates weighted by the number of cases, and then also average the EMR in a similar fashion.  We  take these draws to calculate these ratios and and find the posterior credible intervals.  We sort these hospitals according to the upper bound of the credible interval for this ratio and rank them in this way and find the following top 5 and bottom five hospitals.
```{r, echo = FALSE,strip.white=TRUE, cache = TRUE}
unique.hosp = unique(cs2$hospital.name)
#prob.mat
hosp.ratio.mat = data_frame()
for(hosp in unique.hosp){
  hosp.mat = prob.mat[,which(cs2$hospital.name == hosp)]
  ave.vec = apply(hosp.mat,1,function(x) weighted.mean(x,cs2$number.of.cases[which(cs2$hospital.name == hosp)]))
  ave.epr = weighted.mean(cs2$expected.mortality.rate.real[which(cs2$hospital.name == hosp)],cs2$number.of.cases[which(cs2$hospital.name == hosp)])
  hosp.ratio = ave.vec / ave.epr
  hosp.n = sum(cs2$number.of.cases[which(cs2$hospital.name == hosp)])
  df = data_frame(name = hosp, 
                  hosp.n = hosp.n,
                  lower.ratio = quantile(hosp.ratio,0.025),
                  med.ratio = quantile(hosp.ratio,.5),
                  upper.ratio = quantile(hosp.ratio,.975),
                  prob.above.1 = mean(hosp.ratio > 1))
  hosp.ratio.mat = bind_rows(hosp.ratio.mat,df)
  
}
weighted.hosp.mat = hosp.ratio.mat %>% arrange(upper.ratio)

top_5 = weighted.hosp.mat %>% head(n = 5) %>% bind_cols(rank = 1:5,.) %>%
  rename("Pr(R>1)" = prob.above.1)
bottom_5 = weighted.hosp.mat %>% tail(n=5) %>% bind_cols(rank = 36:40,.) %>%
  rename("Pr(R>1)" = prob.above.1)

rankings = bind_rows(top_5,bottom_5)
```

```{r, echo = FALSE,strip.white=TRUE}
kable(rankings, padding = 0)
```

```{r, echo = FALSE,strip.white=TRUE, eval = FALSE}
kable(bottom_5, padding = 0)
```

##### Objective 7
Using a model based recommendations allow us to take into consideration not only other variables, but it also allows us to quantify our uncertainty more efficiently in our estimates. This uncertainty quantification is crucial in making meaningful recommendations because it allows us to meaningfull account for different circumstances like small case load with very high or low observed mortality rates.


